import os
import json
from dotenv import load_dotenv
from pathlib import Path
import pandas as pd
import mplfinance as mpf
from datetime import datetime
import yfinance as yf
from langchain_core.tools import tool
# ä½¿ç”¨openai å…¼å®¹åƒé—®
from langchain_openai import ChatOpenAI
from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain_core.prompts import ChatPromptTemplate
from ddgs import DDGS
# æ–°å¢ï¼šç”¨äºç®¡ç†è®°å¿†çš„æ¨¡å—
from langchain_core.runnables.history import RunnableWithMessageHistory
# æ–°å¢ï¼šç”¨äºé•¿æ•ˆè®°å¿†æŒä¹…åŒ–çš„æ¨¡å—
from langchain_community.chat_message_histories import FileChatMessageHistory
# æ–°å¢ï¼šç”¨äºRAGçš„æ¨¡å—
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
# æ–°å¢è¿™ä¸ªä¸“é—¨é’ˆå¯¹é˜¿é‡Œäº‘çš„å¼•ç”¨
from langchain_community.embeddings import DashScopeEmbeddings
# æ–°å¢ï¼šå¼•å…¥é«˜çº§ç»ˆç«¯äº¤äº’åº“
from prompt_toolkit import PromptSession
from prompt_toolkit.history import InMemoryHistory
from prompt_toolkit.styles import Style
# ä¼˜åŒ–æ˜¾ç¤ºæ•ˆæœ
from rich.console import Console
from rich.panel import Panel
from langchain.callbacks.base import BaseCallbackHandler

# åˆå§‹åŒ–å¯Œæ–‡æœ¬æ§åˆ¶å°
console = Console()

# åœ¨ç¨‹åºå¯åŠ¨çš„æœ€å¼€å§‹ï¼Œè°ƒç”¨ load_dotenv()
# å®ƒä¼šè‡ªåŠ¨åœ¨å½“å‰ç›®å½•å¯»æ‰¾ .env æ–‡ä»¶ï¼Œå¹¶æŠŠé‡Œé¢çš„å€¼è½½å…¥åˆ°ç³»ç»Ÿç¯å¢ƒå˜é‡ä¸­
load_dotenv()

# å®‰å…¨åœ°è·å– Key
# ä½¿ç”¨ os.getenv() è·å–ï¼Œå¦‚æœ .env é‡Œæ²¡é…ï¼Œå®ƒä¼šè¿”å› None è€Œä¸æ˜¯ç›´æ¥å´©æºƒ
dashscope_key = os.getenv("DASHSCOPE_API_KEY")

# åœ¨ç¨‹åºåˆšå¯åŠ¨æ—¶å°±æ£€æŸ¥å…³é”®ä¾èµ–ï¼Œå¦‚æœæ²¡é… Keyï¼Œç«‹åˆ»é˜»æ–­å¹¶æŠ¥é”™ï¼Œè€Œä¸æ˜¯ç­‰è·‘äº†ä¸€åŠæ‰æ­»æ‰
if not dashscope_key:
    raise ValueError("âŒ è‡´å‘½é”™è¯¯ï¼šæœªåœ¨ .env æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡ä¸­æ‰¾åˆ° DASHSCOPE_API_KEYï¼è¯·æ£€æŸ¥é…ç½®ã€‚")

# å¼ºè¡Œæ¸…é™¤å½“å‰è„šæœ¬çš„ä»£ç†ç¯å¢ƒå˜é‡ï¼Œå¼ºåˆ¶ç›´è¿
os.environ.pop('http_proxy', None)
os.environ.pop('https_proxy', None)
os.environ.pop('ALL_PROXY', None)
os.environ.pop('all_proxy', None)

# å®‰å…¨é…ç½®ï¼šå®šä¹‰ Agent çš„ä¸“å±æ´»åŠ¨æ²™ç®±
# å¼ºåˆ¶è®¾å®šåœ¨å½“å‰è¿è¡Œç›®å½•ä¸‹çš„ "agent_workspace" æ–‡ä»¶å¤¹å†…
SANDBOX_DIR = Path("./agent_workspace").resolve()
# å¯åŠ¨æ—¶è‡ªåŠ¨åˆ›å»ºè¿™ä¸ªå®‰å…¨å±‹
SANDBOX_DIR.mkdir(parents=True, exist_ok=True)

# è®¾å®šå›ºå®šçš„çŸ¥è¯†åº“ç›®å½•
KB_DIR = Path("./knowledge_base").resolve()
KB_DIR.mkdir(parents=True, exist_ok=True) # å¦‚æœæ²¡æœ‰ä¼šè‡ªåŠ¨åˆ›å»º

# å®šä¹‰å…è®¸è¯»å–çš„æ–‡ä»¶åç¼€ç™½åå•
ALLOWED_EXTENSIONS = {'.pdf', '.md', '.txt', '.csv'}

# ğŸŒŸ æ–°å¢ï¼šFAISS å‘é‡ç¡¬ç›˜æŒä¹…åŒ–ç›®å½•
FAISS_DB_DIR = Path("./embeddings").resolve()
FAISS_DB_DIR.mkdir(parents=True, exist_ok=True)

# ğŸŒŸ æ–°å¢ï¼šFAISS å‘é‡åº“å…¨å±€å†…å­˜ç¼“å­˜æ± 
# å­—å…¸ç»“æ„: { "æ–‡ä»¶ç»å¯¹è·¯å¾„": {"mtime": 12345678.9, "vectorstore": <FAISS_Object>} }
FAISS_CACHE = {}

# å®šä¹‰ä¸€ä¸ªä¸“é—¨å­˜æ”¾è®°å¿†ç¢ç‰‡çš„ç›®å½•
MEMORY_DIR = Path("./memory").resolve()
MEMORY_DIR.mkdir(parents=True, exist_ok=True)

# ğŸŒŸ æ–°å¢ï¼šé•¿æœŸè®°å¿†æå–å·¥å…· (LTM)
USER_PROFILE_PATH = Path("./memory/user_profile.json").resolve()

# ==========================================
# æå®¢è§†è§‰æ ¸å¿ƒï¼šè‡ªå®šä¹‰å›è°ƒæ‹¦æˆªå™¨
# ==========================================
class HackerMatrixCallback(BaseCallbackHandler):
    """æ‹¦æˆª Agent çš„å†…éƒ¨æ€è€ƒæµï¼Œå¹¶ç”¨æå…¶èµ›åšæœ‹å…‹çš„æ–¹å¼æ‰“å°åˆ°ç»ˆç«¯"""
    
    def on_agent_action(self, action, **kwargs):
        # å½“ Agent å†³å®šè°ƒç”¨å·¥å…·æ—¶è§¦å‘
        # action.log åŒ…å«å®ƒçš„æ€è€ƒè¿‡ç¨‹ (Thought)
        thought_text = action.log.split("Action:")[0].strip()
        
        # æ‰“å°ç»¿è‰²åŠ ç²—çš„æ€è€ƒè¿‡ç¨‹
        console.print(f"\n[bold green]â–¶ æ ¸å¿ƒæ€è€ƒåè®®æ¥å…¥...[/bold green]")
        console.print(f"[green dim]{thought_text}[/green dim]")
        
        # æ‰“å°äº®è“è‰²çš„å·¥å…·è°ƒç”¨æŒ‡ä»¤
        console.print(f"[bold cyan]âš¡ è§¦å‘æœ¬åœ°ç³»ç»ŸæŒ‡ä»¤:[/bold cyan] [bold yellow]{action.tool}[/bold yellow]")
        console.print(f"[cyan dim]   è½½å…¥å‚æ•°: {action.tool_input}[/cyan dim]")

    def on_tool_end(self, output, **kwargs):
        # å½“å·¥å…·æ‰§è¡Œå®Œæ¯•ï¼Œè¿”å›æ•°æ®æ—¶è§¦å‘
        # æˆªå–å‰ 150 ä¸ªå­—ç¬¦ï¼Œè¥é€ ä¸€ç§æ•°æ®æµå¿«é€Ÿé—ªè¿‡çš„æ„Ÿè§‰
        snippet = str(output)[:150].replace('\n', ' ') + "..."
        console.print(f"[bold magenta]âœ”ï¸ æ•°æ®æµæ•è·æˆåŠŸ:[/bold magenta] [magenta dim]{snippet}[/magenta dim]")

    def on_agent_finish(self, finish, **kwargs):
        # æœ€ç»ˆä»»åŠ¡å®Œæˆæ—¶è§¦å‘
        console.print("\n[bold green]â–“â–“â–“â–“â–“â–“â–“â–“ ä»»åŠ¡æ‰§è¡Œå®Œæ¯• â–“â–“â–“â–“â–“â–“â–“â–“[/bold green]")

# ==========================================
# æ’ä»¶ 1ï¼šé€šè¿‡yahooçš„æ ‡å‡†æ¥å£æŸ¥è¯¢ç¾è‚¡è‚¡ä»·
# ==========================================
@tool
def get_stock_price(ticker: str) -> str:
    """è¾“å…¥ç¾è‚¡ä»£ç ï¼ˆå¦‚ AAPL, MSFTï¼‰ï¼Œè¿”å›è¯¥è‚¡ç¥¨æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥çš„å¼€ç›˜ä»·å’Œæ”¶ç›˜ä»·ã€‚"""
    try:
        stock = yf.Ticker(ticker)
        hist = stock.history(period="1d")
        if hist.empty:
            return f"æœªæ‰¾åˆ° {ticker} çš„æ•°æ®"
        open_p = round(float(hist['Open'].iloc[0]), 2)
        close_p = round(float(hist['Close'].iloc[0]), 2)
        return f"{ticker} æœ€è¿‘äº¤æ˜“æ—¥æ•°æ® - å¼€ç›˜ä»·: {open_p}, æ”¶ç›˜ä»·: {close_p}"
    except Exception as e:
        return f"æŸ¥è¯¢å‡ºé”™: {str(e)}"
    
# ==========================================
# æ’ä»¶ 1.5ï¼šKçº¿å›¾ä¸ 30 å¤©èµ°åŠ¿å¯è§†åŒ–
# ==========================================
@tool
def draw_stock_chart(ticker: str) -> str:
    """
    è·å–æŒ‡å®šç¾è‚¡ä»£ç ï¼ˆå¦‚ AAPL, MSFTï¼‰è¿‡å» 1 ä¸ªæœˆçš„å†å²æ•°æ®ï¼Œç»˜åˆ¶ä¸“ä¸šçš„ Kçº¿èµ°åŠ¿å›¾ä¸æˆäº¤é‡ï¼Œ
    å¹¶å°†å›¾ç‰‡å®‰å…¨ä¿å­˜åœ¨æœ¬åœ°æ²™ç®±ä¸­ã€‚
    å½“ä½ éœ€è¦ä¸ºåˆ†ææŠ¥å‘Šå¢åŠ å¯è§†åŒ–å›¾è¡¨ï¼Œæˆ–è€…ç”¨æˆ·è¦æ±‚æŸ¥çœ‹å†å²èµ°åŠ¿æ—¶ï¼Œè°ƒç”¨æ­¤å·¥å…·ã€‚
    """
    try:
        stock = yf.Ticker(ticker)
        # è·å–è¿‡å» 1 ä¸ªæœˆçš„æ•°æ®ï¼ˆåŒ…å« Open, High, Low, Close, Volumeï¼‰
        hist = stock.history(period="1mo")
        if hist.empty:
            return f"âŒ æœªæ‰¾åˆ° {ticker} çš„å†å²æ•°æ®ï¼Œæ— æ³•ç»˜å›¾ã€‚"

        # ğŸŒŸ æ ¸å¿ƒä¿®å¤ï¼šç§»é™¤ datetime æ—¶é—´æˆ³ï¼Œä½¿ç”¨ç¡®å®šæ€§çš„çº¯ç²¹å‘½åï¼
        # è¿™æ ·å¤§æ¨¡å‹ç»å¯¹ä¸ä¼šå†æ‹¼é”™å›¾ç‰‡è·¯å¾„ï¼Œä¸”èƒ½è‡ªåŠ¨è¦†ç›–æ—§å›¾ï¼Œä¿æŒæ²™ç®±æ•´æ´
        chart_filename = f"{ticker}_30d_chart.png"
        
        # å°†å›¾ç‰‡è·¯å¾„å¼ºåˆ¶é”å®šåœ¨æ²™ç®±ç›®å½•å†… (å¤ç”¨æˆ‘ä»¬ä¹‹å‰çš„é˜²é€ƒé€¸å®‰å…¨å±‹)
        chart_path = (SANDBOX_DIR / chart_filename).resolve()

        # æ ¸å¿ƒç»˜å›¾é€»è¾‘ï¼šä½¿ç”¨ mpf ç”»å‡ºå¸¦å‡çº¿å’Œæˆäº¤é‡çš„é›…è™é£æ ¼ Kçº¿å›¾
        mpf.plot(
            hist, 
            type='candle',       # Kçº¿å›¾æ¨¡å¼
            volume=True,         # æ˜¾ç¤ºåº•éƒ¨æˆäº¤é‡
            style='yahoo',       # é›…è™è´¢ç»é…è‰²é£æ ¼ (çº¢ç»¿æŸ±)
            title=f"{ticker} 30-Day Trend", 
            mav=(5, 10),         # æ·»åŠ  5æ—¥å’Œ 10æ—¥ç§»åŠ¨å‡çº¿
            savefig=str(chart_path) # ç›´æ¥ä¿å­˜åˆ°æ²™ç®±ï¼Œä¸å¼¹çª—
        )

        # æå–æå€¼ï¼Œä½œä¸º prompt è¡¥å……ä¿¡æ¯ä¼ ç»™ LLM
        max_price = round(hist['High'].max(), 2)
        min_price = round(hist['Low'].min(), 2)
        latest_close = round(hist['Close'].iloc[-1], 2)
        
        return (
            f"âœ… {ticker} çš„30å¤©Kçº¿å›¾å·²æˆåŠŸç”Ÿæˆï¼æ–‡ä»¶åä¸ºï¼š{chart_filename}ã€‚\n"
            f"ã€ç»Ÿè®¡æ‘˜è¦ã€‘æœ€é«˜ä»·: {max_price}, æœ€ä½ä»·: {min_price}, æœ€æ–°ä»·: {latest_close}ã€‚\n"
            f"ğŸš¨ã€å¼ºåˆ¶è¯­æ³•ã€‘ï¼šåœ¨ä½ é©¬ä¸Šè¦ç”Ÿæˆçš„ Markdown æŠ¥å‘Šä¸­ï¼Œå¿…é¡»ä¸¥æ ¼ä½¿ç”¨ `![{ticker}èµ°åŠ¿å›¾](./{chart_filename})` æ’å…¥æ­¤å›¾ç‰‡ï¼Œä¸€ä¸ªå­—éƒ½ä¸èƒ½æ”¹ï¼"
        )
    except Exception as e:
        return f"ç»˜åˆ¶å›¾è¡¨å‡ºé”™: {str(e)}"

# ==========================================
# æ’ä»¶ 2ï¼šä»£ç æœç´¢å·¥å…·
# ==========================================
@tool
def search_company_ticker(company_name: str) -> str:
    """
    å½“ä½ ä¸çŸ¥é“æŸå®¶å…¬å¸ã€äº§å“æˆ–å“ç‰Œçš„å…·ä½“ç¾è‚¡è‚¡ç¥¨ä»£ç æ—¶ï¼Œå¿…é¡»å…ˆä½¿ç”¨æ­¤å·¥å…·ã€‚
    è¾“å…¥å…¬å¸æˆ–äº§å“åç§°ï¼ˆå¦‚ 'aws', 'æ·˜å®', 'é©¬æ–¯å…‹çš„å…¬å¸'ï¼‰ï¼Œå®ƒä¼šè”ç½‘æœç´¢å¹¶è¿”å›ç›¸å…³ä¿¡æ¯ä»¥ä¾›ä½ æå–è‚¡ç¥¨ä»£ç ã€‚
    """
    try:
        # è‡ªåŠ¨æ„é€ æœç´¢è¯ï¼ŒæŠ“å–å‰ 3 æ¡ç½‘é¡µæ‘˜è¦
        query = f"{company_name} stock ticker symbol ç¾è‚¡ä»£ç "
        results = DDGS().text(query, max_results=3)
        if not results:
            return f"æœªæœç´¢åˆ° {company_name} çš„ç›¸å…³è‚¡ç¥¨ä»£ç ã€‚"
        
        # å°†æœç´¢åˆ°çš„ç½‘é¡µæ‘˜è¦ç›´æ¥æ‰”ç»™å¤§æ¨¡å‹ï¼Œå®ƒçš„â€œå¤§è„‘â€ä¼šè‡ªåŠ¨ä»é‡Œé¢æå–å‡ºæ­£ç¡®çš„å­—æ¯ä»£ç 
        return str(results)
    except Exception as e:
        return f"è”ç½‘æœç´¢å‡ºé”™: {str(e)}"

# ==========================================
# æ’ä»¶ 3ï¼šè¯»å–æœ¬åœ°æ–‡ä»¶
# ==========================================
@tool
def read_local_file(file_path: str) -> str:
    """
    å½“éœ€è¦è¯»å–æœ¬åœ°æ²™ç®±ä¸­çš„æ–‡ä»¶å†…å®¹ï¼ˆå¦‚ä¹‹å‰ç”Ÿæˆçš„æŠ¥å‘Šï¼‰æ—¶è°ƒç”¨æ­¤å·¥å…·ã€‚
    è¾“å…¥å‚æ•°ä¸ºæ²™ç®±å†…çš„æ–‡ä»¶åæˆ–ç›¸å¯¹è·¯å¾„ï¼ˆä¾‹å¦‚ï¼š'report.md' æˆ– 'data/info.txt'ï¼‰ã€‚
    æ³¨æ„ï¼šå‡ºäºå®‰å…¨é™åˆ¶ï¼Œä½ åªèƒ½è¯»å–æ²™ç®±(agent_workspace)å†…çš„æ–‡ä»¶ã€‚
    """
    try:
        # 1. è·¯å¾„æ‹¼æ¥ä¸ç»å¯¹è·¯å¾„è§£æ
        target_path = (SANDBOX_DIR / file_path).resolve()
        
        # 2. ğŸŒŸ æ ¸å¿ƒé˜²å¾¡ï¼šä½¿ç”¨ is_relative_to æ›¿ä»£ startswith
        # è¿™æ˜¯ Python 3.9+ æä¾›çš„åŸç”Ÿæ–¹æ³•ï¼Œå®ƒæŒ‰å±‚çº§ä¸¥æ ¼åˆ¤æ–­ï¼Œå½»åº•æœç»å¹³çº§æ¶æ„ç›®å½•çš„ç»•è¿‡
        if not target_path.is_relative_to(SANDBOX_DIR):
            return "âŒ å®‰å…¨æ‹¦æˆªï¼šæ¢æµ‹åˆ°è¶Šæƒæ“ä½œï¼ä½ è¯•å›¾è¯»å–æ²™ç®±å¤–éƒ¨çš„æ–‡ä»¶ï¼Œå·²è¢«ç³»ç»Ÿæ‹’ç»ã€‚"

        # 3. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not target_path.exists():
            return f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {target_path.name}"
            
        # 4. å®‰å…¨æ‰§è¡Œè¯»å–
        with open(target_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        return f"æ–‡ä»¶ {target_path.name} çš„å†…å®¹æ˜¯:\n{content}"
        
    except Exception as e:
        return f"è¯»å–æ–‡ä»¶å‡ºé”™: {str(e)}"

# ==========================================
# æ’ä»¶ 4ï¼šå†™å…¥æœ¬åœ°æ–‡ä»¶
# ==========================================
@tool
def write_local_file(file_path: str, content: str) -> str:
    """
    ğŸš¨ã€å¼ºåˆ¶äº¤ä»˜é€šé“ã€‘ï¼š
    å½“ä½ è¢«è¦æ±‚â€œå†™æŠ¥å‘Šâ€ã€â€œç”Ÿæˆåˆ†æâ€ã€â€œä¿å­˜åˆ°æœ¬åœ°â€æ—¶ï¼Œ**ç»å¯¹ç¦æ­¢**åœ¨èŠå¤©çª—å£ç›´æ¥è¾“å‡º Markdown æ–‡æœ¬ï¼
    ä½ å¿…é¡»ä¸”åªèƒ½è°ƒç”¨æ­¤å·¥å…·ï¼Œå°†å®Œæ•´æ’ç‰ˆå¥½çš„ Markdown å†…å®¹ä½œä¸º `content` å‚æ•°ä¼ å…¥ã€‚
    è¾“å…¥å‚æ•° file_path ä¸ºç›®æ ‡æ–‡ä»¶åï¼ˆä¾‹å¦‚ï¼š'report.md'ï¼‰ã€‚
    """
    try:
        # 1. è·¯å¾„æ‹¼æ¥ä¸ç»å¯¹è·¯å¾„è§£æ (æ ¸å¿ƒé˜²å¾¡æ­¥ 1)
        # å³ä½¿å¤§æ¨¡å‹ä¼ å…¥ç±»ä¼¼ '../../éšè—ç›®å½•/å±é™©æ–‡ä»¶.txt' çš„æ¶æ„è·¯å¾„ï¼Œ
        # .resolve() ä¹Ÿä¼šåœ¨åº•å±‚å°†å…¶æ‹‰ç›´ï¼Œè®¡ç®—å‡ºçœŸå®çš„ç»å¯¹è·¯å¾„ã€‚
        target_path = (SANDBOX_DIR / file_path).resolve()
        
        # 2. è¶Šæƒåˆ¤å®š (æ ¸å¿ƒé˜²å¾¡æ­¥ 2)
        # æ£€æŸ¥è§£æåçš„æœ€ç»ˆçœŸå®è·¯å¾„ï¼Œæ˜¯ä¸æ˜¯ä»¥æˆ‘ä»¬çš„æ²™ç®±ç›®å½•ä¸ºå¼€å¤´çš„
        # å¦‚æœä¸æ˜¯ï¼Œè¯´æ˜å®ƒç”¨ ../ æˆåŠŸé€ƒé€¸åˆ°äº†ä¸Šå±‚ç›®å½•ï¼Œç›´æ¥æ‹¦æˆªï¼
        # å°† startswith æ›¿æ¢ä¸ºåº•å±‚çš„å±‚çº§åˆ¤å®š
        if not target_path.is_relative_to(SANDBOX_DIR):
            return "âŒ å®‰å…¨æ‹¦æˆªï¼šæ¢æµ‹åˆ°è¶Šæƒæ“ä½œï¼ä½ è¯•å›¾å°†æ–‡ä»¶å†™å…¥æ²™ç®±å¤–éƒ¨ï¼Œå·²è¢«ç³»ç»Ÿæ‹’ç»ã€‚"

        # 3. ç¡®ä¿æ²™ç®±å†…çš„åˆæ³•å­ç›®å½•å­˜åœ¨
        target_path.parent.mkdir(parents=True, exist_ok=True)
        
        # 4. å®‰å…¨æ‰§è¡Œå†™å…¥
        with open(target_path, 'w', encoding='utf-8') as f:
            f.write(content)
            
        return f"âœ… æˆåŠŸï¼æŠ¥å‘Šå·²å®‰å…¨å†™å…¥æ²™ç®±: {target_path}"
        
    except Exception as e:
        return f"å†™å…¥æ–‡ä»¶å‡ºé”™: {str(e)}"

# ==========================================
# æ’ä»¶ 5ï¼šRAG æœ¬åœ°æ–‡æ¡£æ£€ç´¢å™¨ (L1å†…å­˜ + L2ç¡¬ç›˜ æ··åˆæŒä¹…åŒ–æ¶æ„)
# ==========================================
@tool
def analyze_local_document(file_name: str, query: str) -> str:
    """
    åˆ†æçŸ¥è¯†åº“ä¸­çš„æ–‡æ¡£ï¼ˆæ”¯æŒ PDFã€Markdownã€TXT ç­‰ï¼‰å¹¶å›ç­”é—®é¢˜ã€‚
    è¾“å…¥å‚æ•° file_name åªéœ€è¦æä¾›æ–‡ä»¶åï¼ˆä¾‹å¦‚ 'report.pdf' æˆ– 'readme.md'ï¼‰ï¼Œä¸è¦æä¾›å®Œæ•´è·¯å¾„ï¼
    """
    try:
        target_path = (KB_DIR / file_name).resolve()
        
        # å®‰å…¨æ‹¦æˆª
        if not target_path.is_relative_to(KB_DIR):
            return "âŒ å®‰å…¨æ‹¦æˆªï¼šä½ è¯•å›¾è¯»å–çŸ¥è¯†åº“ä»¥å¤–çš„æ–‡ä»¶ï¼"

        if not target_path.exists():
            return f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {file_name}ã€‚è¯·å…ˆä½¿ç”¨ list_kb_files å·¥å…·æŸ¥çœ‹å½“å‰æœ‰å“ªäº›æ–‡ä»¶ã€‚"
            
        current_mtime = os.path.getmtime(target_path)
        target_path_str = str(target_path)
        
        # ä¸ºè¯¥æ–‡ä»¶è®¡ç®—ä¸“å±çš„ç¡¬ç›˜ç¼“å­˜ç›®å½•å
        doc_cache_dir = FAISS_DB_DIR / f"{file_name}_vstore"
        meta_file = doc_cache_dir / "meta.json"
        
        embeddings = DashScopeEmbeddings(
            dashscope_api_key=dashscope_key,
            model="text-embedding-v3", 
        )
        
        # ==========================================
        # âš¡ æ£€æŸ¥ L1 ç¼“å­˜ (å†…å­˜)
        # ==========================================
        if target_path_str in FAISS_CACHE and FAISS_CACHE[target_path_str]["mtime"] == current_mtime:
            console.print(f"[bold yellow]âš¡ L1 å‘½ä¸­ (å†…å­˜):[/bold yellow] [yellow dim]æé€Ÿå¤ç”¨ {file_name} çš„å‘é‡ç´¢å¼•[/yellow dim]")
            vectorstore = FAISS_CACHE[target_path_str]["vectorstore"]
            
        else:
            # ==========================================
            # ğŸ’¾ æ£€æŸ¥ L2 ç¼“å­˜ (ç¡¬ç›˜)
            # ==========================================
            loaded_from_disk = False
            if doc_cache_dir.exists() and meta_file.exists():
                try:
                    with open(meta_file, 'r', encoding='utf-8') as f:
                        meta = json.load(f)
                    
                    # æ ¡éªŒç¡¬ç›˜ç¼“å­˜çš„æ—¶é—´æˆ³æ˜¯å¦ä¸æ–‡ä»¶å½“å‰æ—¶é—´ä¸€è‡´
                    if meta.get("mtime") == current_mtime:
                        console.print(f"[bold cyan]ğŸ’¾ L2 å‘½ä¸­ (ç¡¬ç›˜):[/bold cyan] [cyan dim]åŠ è½½ {file_name} çš„æŒä¹…åŒ–ç´¢å¼•å¹¶å†™å›å†…å­˜[/cyan dim]")
                        # æ³¨æ„ï¼šallow_dangerous_deserialization=True æ˜¯å¿…é¡»çš„ï¼Œå› ä¸ºæˆ‘ä»¬è¦ä¿¡ä»»è‡ªå·±æœ¬åœ°ç”Ÿæˆçš„ pickle æ–‡ä»¶
                        vectorstore = FAISS.load_local(
                            str(doc_cache_dir), 
                            embeddings, 
                            allow_dangerous_deserialization=True 
                        )
                        # åå‘é¢„çƒ­ L1 å†…å­˜æ± 
                        FAISS_CACHE[target_path_str] = {"mtime": current_mtime, "vectorstore": vectorstore}
                        loaded_from_disk = True
                except Exception as e:
                    console.print(f"[bold red]è¯»å–ç¡¬ç›˜ç¼“å­˜å¤±è´¥ï¼Œå‡†å¤‡é™çº§é‡å»º: {str(e)}[/bold red]")
            
            # ==========================================
            # ğŸ”„ å‡æœªå‘½ä¸­ (æˆ–æ–‡ä»¶è¢«ä¿®æ”¹)ï¼šè§¦å‘ L3 é‡å»ºå¹¶ç©¿é€å†™å…¥
            # ==========================================
            if not loaded_from_disk:
                console.print(f"[bold blue]ğŸ”„ æ„å»ºç´¢å¼•:[/bold blue] [blue dim]æ­£åœ¨å¯¹ {file_name} è¿›è¡Œè§£æã€å‘é‡åŒ–ä¸æŒä¹…åŒ–...[/blue dim]")
                
                ext = target_path.suffix.lower()
                if ext == '.pdf':
                    loader = PyPDFLoader(target_path_str)
                elif ext in ['.md', '.txt', '.csv']:
                    loader = TextLoader(target_path_str, encoding='utf-8')
                else:
                    return f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {ext}ã€‚ç›®å‰æ”¯æŒ {ALLOWED_EXTENSIONS}"

                docs = loader.load()
                text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
                raw_splits = text_splitter.split_documents(docs)
                splits = [s for s in raw_splits if s.page_content.strip()]
                
                if not splits:
                    return f"âŒ æ–‡ä»¶ {file_name} å†…å®¹ä¸ºç©ºï¼Œæˆ–è€…æ— æ³•æå–æœ‰æ•ˆæ–‡æœ¬ã€‚"
                
                # æ„å»ºæ–°çš„å‘é‡åº“
                vectorstore = FAISS.from_documents(splits, embeddings)
                
                # å†™å…¥ L1 å†…å­˜
                FAISS_CACHE[target_path_str] = {"mtime": current_mtime, "vectorstore": vectorstore}
                
                # å†™å…¥ L2 ç¡¬ç›˜
                doc_cache_dir.mkdir(parents=True, exist_ok=True)
                vectorstore.save_local(str(doc_cache_dir))
                with open(meta_file, 'w', encoding='utf-8') as f:
                    json.dump({"mtime": current_mtime, "file_name": file_name}, f)

        # æ‰§è¡ŒçœŸæ­£çš„æ£€ç´¢æ“ä½œ
        retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
        relevant_docs = retriever.invoke(query)
        
        context = "\n---\n".join([doc.page_content for doc in relevant_docs])
        return f"âœ… ä»æ–‡æ¡£ {file_name} ä¸­æ£€ç´¢åˆ°ä»¥ä¸‹æ ¸å¿ƒä¿¡æ¯ï¼š\n{context}\n\nè¯·æ ¹æ®ä»¥ä¸Šæ•°æ®å›ç­”ã€‚"
        
    except Exception as e:
        return f"è§£ææˆ–æ£€ç´¢æ–‡æ¡£å‡ºé”™: {str(e)}"

# ==========================================
# æ’ä»¶ 6ï¼šç»™ Agent ä¸€åŒâ€œçœ¼ç›â€å»æŸ¥çœ‹çŸ¥è¯†åº“
# ==========================================
@tool
def list_kb_files() -> str:
    """
    å½“ç”¨æˆ·è®©ä½ ä»çŸ¥è¯†åº“æœç´¢ï¼Œæˆ–è€…ä½ ä¸çŸ¥é“å…·ä½“æ–‡ä»¶åæ—¶ï¼Œå¿…é¡»å…ˆè°ƒç”¨æ­¤å·¥å…·ï¼
    å®ƒä¼šè¿”å›çŸ¥è¯†åº“æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰å¯ç”¨çš„æ–‡ä»¶åˆ—è¡¨ã€‚
    """
    try:
        # æ‰«æç™½åå•å†…çš„æ‰€æœ‰æ–‡ä»¶
        files = [f.name for f in KB_DIR.iterdir() if f.is_file() and f.suffix.lower() in ALLOWED_EXTENSIONS]
        if not files:
            return "å½“å‰çŸ¥è¯†åº“æ–‡ä»¶å¤¹ä¸ºç©ºï¼Œæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ”¯æŒçš„æ–‡ä»¶ã€‚"
        return f"çŸ¥è¯†åº“ä¸­å½“å‰æœ‰ä»¥ä¸‹æ–‡ä»¶å¯ä»¥è¯»å–:\n" + "\n".join(files)
    except Exception as e:
        return f"è¯»å–ç›®å½•å‡ºé”™: {str(e)}"

# ==========================================
# æ’ä»¶ 7ï¼šé•¿æœŸè®°å¿†æå–
# ==========================================
@tool
def remember_user_fact(fact: str) -> str:
    """
    ğŸš¨ã€è®°å¿†å†™å…¥æŒ‡ä»¤ã€‘ï¼š
    å½“ä½ å¾—çŸ¥å…³äºç”¨æˆ·çš„å…³é”®ä¿¡æ¯ï¼ˆå¦‚ï¼šæŒä»“æƒ…å†µã€æˆæœ¬ä»·ã€æŠ•èµ„åå¥½ã€ä¸ªäººä¹ æƒ¯ç­‰ï¼‰æ—¶ï¼Œå¿…é¡»è°ƒç”¨æ­¤å·¥å…·ã€‚
    è¾“å…¥å‚æ•° fact æ˜¯ä¸€å¥ç®€çŸ­çš„å®¢è§‚äº‹å®æè¿°ï¼Œä¾‹å¦‚ï¼š"ç”¨æˆ·æŒæœ‰ 100 è‚¡ TSLA" æˆ– "ç”¨æˆ·ä¸å–œæ¬¢çœ‹é•¿ç¯‡å¤§è®º"ã€‚
    """
    try:
        # ç¡®ä¿æ–‡ä»¶å­˜åœ¨
        if not USER_PROFILE_PATH.exists():
            USER_PROFILE_PATH.parent.mkdir(parents=True, exist_ok=True)
            with open(USER_PROFILE_PATH, 'w', encoding='utf-8') as f:
                json.dump({"facts": []}, f)
                
        with open(USER_PROFILE_PATH, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # é˜²æ­¢é‡å¤å†™å…¥
        if fact not in data["facts"]:
            data["facts"].append(fact)
            with open(USER_PROFILE_PATH, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return f"âœ… é•¿æœŸè®°å¿†å·²æ›´æ–°ï¼š{fact}"
        return "è¯¥è®°å¿†å·²å­˜åœ¨ã€‚"
    except Exception as e:
        return f"è®°å¿†å†™å…¥å¤±è´¥: {str(e)}"

tools = [get_stock_price, draw_stock_chart, search_company_ticker, read_local_file, write_local_file, list_kb_files, analyze_local_document, remember_user_fact]

# ==========================================
# ğŸ§  é…ç½®é•¿æ•ˆè®°å¿†å¼•æ“ (Long-Term Memory)
# ==========================================

def get_session_history(session_id: str):
    """
    å¸¦æœ‰æ»‘åŠ¨çª—å£æˆªæ–­æœºåˆ¶çš„çŸ­æœŸè®°å¿†å¼•æ“ã€‚
    """
    memory_file = str(MEMORY_DIR / f"{session_id}.json")
    history = FileChatMessageHistory(memory_file)
    
    # ğŸŒŸ æ ¸å¿ƒçœé’±é€»è¾‘ï¼šæ»‘åŠ¨çª—å£æˆªæ–­
    # å¦‚æœå¯¹è¯è¶…è¿‡ 10 æ¡ï¼ˆ5æ¬¡é—®ç­”ï¼‰ï¼Œæˆ‘ä»¬å°±æŠŠæ›´æ—©çš„é€å­—ç¨¿æ¸…ç†æ‰ï¼Œåªä¿ç•™æœ€æ–°çš„ 10 æ¡ã€‚
    # é‚£äº›é‡è¦çš„å†å²ä¿¡æ¯ï¼Œå·²ç»è¢«å¤§æ¨¡å‹ç”¨ remember_user_fact å­˜è¿› user_profile é‡Œé¢äº†ï¼
    if len(history.messages) > 10:
        kept_messages = history.messages[-10:]
        history.clear() # æ¸…ç©ºè‡ƒè‚¿çš„æ–‡ä»¶
        for msg in kept_messages:
            history.add_message(msg) # æŠŠæœ€æ–°çš„ 10 æ¡å†™å›å»
            
    return history

def get_user_profile():
    """è¯»å–ç”¨æˆ·é•¿æœŸè®°å¿†æ ¸å¿ƒï¼Œè½¬åŒ–ä¸ºå­—ç¬¦ä¸²æ³¨å…¥ Prompt"""
    if not USER_PROFILE_PATH.exists():
        return "æš‚æ— é•¿æœŸè®°å¿†"
    try:
        with open(USER_PROFILE_PATH, 'r', encoding='utf-8') as f:
            data = json.load(f)
        if not data.get("facts"):
            return "æš‚æ— é•¿æœŸè®°å¿†"
        return "\n".join([f"- {fact}" for fact in data["facts"]])
    except:
        return "æš‚æ— é•¿æœŸè®°å¿†"

# ä½¿ç”¨ ChatOpenAI åŒ…è£…å™¨ï¼Œä½†æŠŠåº•å±‚è¯·æ±‚åœ°å€æŒ‡å‘é˜¿é‡Œäº‘
llm = ChatOpenAI(
    model="qwen3.5-plus", # å¼ºçƒˆæ¨èç”¨ qwen-maxï¼Œå¤„ç†å¤æ‚é€»è¾‘å’Œå¤šå·¥å…·è·¯ç”±æœ€ç¨³
    api_key=dashscope_key,
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1", # æ ¸å¿ƒï¼šæŒ‡å‘é˜¿é‡Œå…¼å®¹æ¥å£
    temperature=0
)

prompt = ChatPromptTemplate.from_messages([
    ("system", """ä½ æ˜¯ä¸€ä¸ªæå®¢é£æ ¼çš„å…¨æ ˆé‡åŒ–åˆ†æå¸ˆä¸ç³»ç»ŸåŠ©æ‰‹ã€‚
     ğŸ§  ã€ç”¨æˆ·çš„é•¿æœŸè®°å¿†åº“ã€‘(ä»¥ä¸‹æ˜¯å…³äºç”¨æˆ·çš„å®¢è§‚äº‹å®ï¼Œè¯·åœ¨åˆ†ææ—¶ä¸»åŠ¨ç»“åˆä½¿ç”¨){user_profile}ã€‚
     å·¥ä½œæµå¦‚ä¸‹ï¼š
    1. ğŸ” æ ¸å¿ƒèƒ½åŠ›ï¼šé‡åˆ°ä¸çŸ¥é“çš„å…¬å¸ç”¨ search_company_tickerï¼ŒæŸ¥æœ€æ–°ä»·æ ¼ç”¨ get_stock_priceï¼ŒæŸ¥30å¤©èµ°åŠ¿å¹¶ç”»å›¾ç”¨ draw_stock_chartï¼ŒæŸ¥æœ¬åœ°èµ„æ–™ç”¨ analyze_local_documentã€‚
    2. âœï¸ æ™ºèƒ½è¾“å‡ºè°ƒåº¦ï¼ˆæœ€é«˜æ³•åˆ™ï¼‰ï¼š
       - âš¡ è½»é‡çº§é—®ç­”ï¼šå¦‚æœç”¨æˆ·åªæ˜¯å•çº¯è¯¢é—®ä»·æ ¼æˆ–ç®€å•é—®é¢˜ï¼Œè¯·ç›´æ¥åœ¨ç»ˆç«¯ç®€æ˜æ‰¼è¦åœ°å›ç­”ï¼Œç»å¯¹ä¸è¦è°ƒç”¨ write_local_fileã€‚
       - ğŸ“ æ·±åº¦æŠ¥å‘Šç”Ÿæˆï¼šå½“ç”¨æˆ·è¦æ±‚â€œç”ŸæˆæŠ¥å‘Šâ€ã€â€œä¿å­˜åˆ°æœ¬åœ°â€ã€â€œå†™ç ”æŠ¥â€æ—¶ï¼Œä½ å¿…é¡»æ•´åˆåˆ†æã€‚
       
    ğŸš¨ã€ç»å¯¹çº¢çº¿æŒ‡ä»¤ - æŠ¥å‘Šæ€ä¹ˆå†™ã€‘ï¼š
    å¦‚æœä½ åˆ¤æ–­å½“å‰ä»»åŠ¡éœ€è¦ç”ŸæˆæŠ¥å‘Šï¼Œä½ **ä¸¥ç¦**åœ¨æœ€ç»ˆçš„ç»ˆç«¯å›å¤ï¼ˆFinal Answerï¼‰ä¸­ç›´æ¥è¾“å‡ºæŠ¥å‘Šçš„ Markdown æ–‡æœ¬ï¼
    ä½ **å¿…é¡»ä¸”åªèƒ½**å°†å†™å¥½çš„æ•´ç¯‡ Markdown å†…å®¹ä½œä¸º `content` å‚æ•°ï¼Œè°ƒç”¨ `write_local_file` å·¥å…·ä¿å­˜ï¼
    ç»ˆç«¯æœ€ç»ˆåªéœ€å†·é…·åœ°æ±‡æŠ¥ä¸€å¥ï¼šâ€œâœ… ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ã€‚æ·±åº¦åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆï¼Œæœ¬åœ°è·¯å¾„ä¸ºï¼šxxxâ€ã€‚
    
    3. ğŸ–¼ï¸ å›¾æ–‡å¹¶èŒ‚ï¼šç”ŸæˆæŠ¥å‘Šæ—¶ï¼Œè¯·åŠ¡å¿…å…ˆè°ƒç”¨ draw_stock_chart ç”Ÿæˆèµ°åŠ¿å›¾ï¼Œå¹¶åœ¨ä¼ ç»™ write_local_file çš„ Markdown å†…å®¹ä¸­ï¼Œä½¿ç”¨ `![å›¾è¡¨](./xxx.png)` å°†å›¾ç‰‡åµŒå…¥ã€‚
    4. ğŸ§  è®°å¿†ç³»ç»Ÿï¼šç»“åˆç”¨æˆ·å†å²å‘ŠçŸ¥ä½ çš„æŒä»“æƒ…å†µæˆ–åå¥½è¿›è¡Œè§£è¯»ã€‚"""),
    ("placeholder", "{chat_history}"),
    ("human", "{input}"),
    ("placeholder", "{agent_scratchpad}"),
])

agent = create_tool_calling_agent(llm, tools, prompt)

# æç¤ºï¼šè¿™é‡Œæˆ‘æŠŠ verbose æ”¹æˆäº† Falseï¼Œè¿™æ ·ç»ˆç«¯é‡Œå°±ä¸ä¼šæ‰“å°å¤§æ®µçš„æ€è€ƒè¿‡ç¨‹ï¼Œæ›´åƒçœŸäººåœ¨èŠå¤©
# å¦‚æœä½ æƒ³çœ‹å®ƒè°ƒç”¨å·¥å…·çš„åº•å±‚ç»†èŠ‚ï¼Œå¯ä»¥æ”¹å› True
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False) 

# ä½¿ç”¨ RunnableWithMessageHistory åŒ…è£…åŸæœ‰çš„æ‰§è¡Œå™¨
# å®ƒä¼šåœ¨æ¯æ¬¡è°ƒç”¨å‰è‡ªåŠ¨æŠŠ memory é‡Œçš„å†å²å¡è¿› {chat_history}ï¼Œå¹¶åœ¨è°ƒç”¨åæŠŠæ–°å¯¹è¯å­˜èµ·æ¥
agent_with_chat_history = RunnableWithMessageHistory(
    agent_executor,
    get_session_history,
    input_messages_key="input",
    history_messages_key="chat_history",
)

# ==========================================
# ç»ˆç«¯äº¤äº’ä¸»å¾ªç¯ (REPL)
# ==========================================
if __name__ == "__main__":
    print("\nğŸ¤– è‚¡ç¥¨åˆ†æ Agent å·²å¯åŠ¨ï¼(è¾“å…¥ 'quit', 'exit' æˆ– 'é€€å‡º' ç»“æŸå¯¹è¯)")
    print("-" * 60)
    
    # åˆå§‹åŒ–é«˜çº§ä¼šè¯ï¼ˆå¸¦å†…å­˜å†å²è®°å½•ï¼‰
    # è¿™æ ·ä½ ä¸ä»…èƒ½å·¦å³ç§»åŠ¨å…‰æ ‡ä¿®æ”¹é”™è¯¯ï¼Œè¿˜èƒ½æŒ‰â€œä¸Š/ä¸‹æ–¹å‘é”®â€è°ƒå‡ºä¸Šä¸€è½®é—®è¿‡çš„é—®é¢˜ï¼
    session = PromptSession(history=InMemoryHistory())
    
    # è‡ªå®šä¹‰ä¸€ä¸ªå¥½çœ‹çš„æç¤ºç¬¦æ ·å¼ï¼ˆå¯é€‰ï¼Œè®©ç•Œé¢æ›´æœ‰æå®¢æ„Ÿï¼‰
    style = Style.from_dict({
        'prompt': 'ansicyan bold', # æç¤ºç¬¦ç”¨é’è‰²åŠ ç²—
    })

    while True:
        try:
            # 1. ä½¿ç”¨é«˜çº§ prompt æ›¿ä»£åŸç”Ÿçš„ input()
            # è¿™é‡Œçš„è¾“å…¥ä½“éªŒå°†æå…¶ä¸æ»‘ï¼Œæ”¯æŒæ‰€æœ‰å¿«æ·é”®å’Œå…‰æ ‡ç§»åŠ¨
            user_input = session.prompt('\nä½ : ', style=style)
            
            # 2. è®¾ç½®é€€å‡ºæ¡ä»¶
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                print("Agent: å†è§ï¼ç¥ä½ æŠ•èµ„é¡ºåˆ©ã€‚")
                break
                
            # é˜²æ­¢è¾“å…¥ç©ºå­—ç¬¦æŠ¥é”™
            if not user_input.strip():
                continue
                
            # 3. å°†è¾“å…¥å‘ç»™å¸¦æœ‰è®°å¿†çš„ Agent
            response = agent_with_chat_history.invoke(
                {
                    "input": user_input,
                    "user_profile": get_user_profile() # ğŸŒŸ æ¯æ¬¡å¯¹è¯å‰ï¼ŒåŠ¨æ€è¯»å–å¹¶æ³¨å…¥é•¿æœŸè®°å¿†ï¼
                },
                config={
                    "configurable": {"session_id": "terminal_session_01"},
                    "callbacks": [HackerMatrixCallback()] # ğŸŒŸ åœ¨è¿™é‡ŒæŒ‚è½½é»‘å®¢è§†è§‰æ»¤é•œï¼
                }
            )
            
            # 4. ç”¨ Rich Panel æ‰“å° Agent çš„æœ€ç»ˆç®€çŸ­å›å¤
            console.print(Panel(
                response['output'], 
                title="[bold cyan]SYS.RESPONSE[/bold cyan]", 
                border_style="cyan"
            ))
            
        except KeyboardInterrupt:
            # æ•æ‰ Ctrl+Cï¼Œé˜²æ­¢ç¨‹åºç›´æ¥å´©æºƒæŠ¥é”™é€€å‡ºï¼Œè€Œæ˜¯ä¼˜é›…åœ°ä¸­æ­¢å½“å‰è¾“å…¥
            print("\n[æ“ä½œå–æ¶ˆï¼ŒæŒ‰é€€å‡ºæŒ‡ä»¤ç»“æŸç¨‹åº]")
            continue
        except EOFError:
            # æ•æ‰ Ctrl+D ä¼˜é›…é€€å‡º
            print("\nAgent: å†è§ï¼")
            break
        except Exception as e:
            print(f"\n[ç³»ç»ŸæŠ¥é”™]: {str(e)}")